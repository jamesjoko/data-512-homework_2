{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "086de1b1",
   "metadata": {},
   "source": [
    "# Homework 2 - Considering Bias in Data\n",
    "# Name: James Joko (jjoko)\n",
    "## License\n",
    "The \"CONSTANTS\" and \"PROCEDURES/FUNCTIONS\" cells in this notebook contains code developed by Dr. David W. McDonald for use in DATA 512, a course in the UW MS Data Science degree program. This code is provided under the Creative Commons CC-BY license. The changes made include subtituting my email for request headers and inserting my access token.\n",
    "\n",
    "For reproducibility, execute each cell from top to bottom."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f4e7e7",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Importing necessary libraries and datasets. The `us_cities_by_state_SEPT.2023.csv` dataset contains duplicate rows. I delete duplicates to reduce computation time and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39fe3559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, time, urllib.parse, pandas as pd, requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4f3878fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>page_title</th>\n",
       "      <th>url</th>\n",
       "      <th>revision_id</th>\n",
       "      <th>article_quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Abbeville, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abbeville,_Alabama</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Adamsville, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Adamsville,_Alabama</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Addison, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Addison,_Alabama</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Akron, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Akron,_Alabama</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabaster, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Alabaster,_Alabama</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     state           page_title  \\\n",
       "0  Alabama   Abbeville, Alabama   \n",
       "1  Alabama  Adamsville, Alabama   \n",
       "2  Alabama     Addison, Alabama   \n",
       "3  Alabama       Akron, Alabama   \n",
       "4  Alabama   Alabaster, Alabama   \n",
       "\n",
       "                                                 url revision_id  \\\n",
       "0   https://en.wikipedia.org/wiki/Abbeville,_Alabama        None   \n",
       "1  https://en.wikipedia.org/wiki/Adamsville,_Alabama        None   \n",
       "2     https://en.wikipedia.org/wiki/Addison,_Alabama        None   \n",
       "3       https://en.wikipedia.org/wiki/Akron,_Alabama        None   \n",
       "4   https://en.wikipedia.org/wiki/Alabaster,_Alabama        None   \n",
       "\n",
       "  article_quality  \n",
       "0            None  \n",
       "1            None  \n",
       "2            None  \n",
       "3            None  \n",
       "4            None  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities = pd.read_csv(\"starting_data/us_cities_by_state_SEPT.2023.csv\").drop_duplicates().reset_index(drop=True)\n",
    "cities['revision_id'] = None\n",
    "cities['article_quality'] = None\n",
    "cities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1a1688",
   "metadata": {},
   "source": [
    "The given dataset does not have Connecticut or Nebraska."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f2c9d0",
   "metadata": {},
   "source": [
    "# Step 2: Getting Article Quality Predictions\n",
    "Define constants and a function that gets the revision ID of an article in the `us_cities_by_state_SEPT.2023.csv` dataset by calling the Wikipedia API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9ef6e1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    CONSTANTS\n",
    "#\n",
    "\n",
    "# The basic English Wikipedia API endpoint\n",
    "API_ENWIKIPEDIA_ENDPOINT = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "# We'll assume that there needs to be some throttling for these requests - we should always be nice to a free data resource\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = (1.0/100.0)-API_LATENCY_ASSUMED\n",
    "\n",
    "# When making automated requests we should include something that is unique to the person making the request\n",
    "# This should include an email - your UW email would be good to put in there\n",
    "REQUEST_HEADERS = {\n",
    "    'User-Agent': 'jjoko@uw.edu, University of Washington, MSDS DATA 512 - AUTUMN 2023',\n",
    "}\n",
    "\n",
    "# This is a string of additional page properties that can be returned see the Info documentation for\n",
    "# what can be included. If you don't want any this can simply be the empty string\n",
    "PAGEINFO_EXTENDED_PROPERTIES = \"talkid|url|watched|watchers\"\n",
    "#PAGEINFO_EXTENDED_PROPERTIES = \"\"\n",
    "\n",
    "# This template lists the basic parameters for making this\n",
    "PAGEINFO_PARAMS_TEMPLATE = {\n",
    "    \"action\": \"query\",\n",
    "    \"format\": \"json\",\n",
    "    \"titles\": \"\",           # to simplify this should be a single page title at a time\n",
    "    \"prop\": \"info\",\n",
    "    \"inprop\": PAGEINFO_EXTENDED_PROPERTIES\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4a7d5169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    #########\n",
    "#\n",
    "#    PROCEDURES/FUNCTIONS\n",
    "#\n",
    "#\n",
    "\n",
    "def request_pageinfo_per_article(article_title = None, \n",
    "                                 endpoint_url = API_ENWIKIPEDIA_ENDPOINT, \n",
    "                                 request_template = PAGEINFO_PARAMS_TEMPLATE,\n",
    "                                 headers = REQUEST_HEADERS):\n",
    "    \n",
    "    # article title can be as a parameter to the call or in the request_template\n",
    "    if article_title:\n",
    "        request_template['titles'] = article_title\n",
    "\n",
    "    if not request_template['titles']:\n",
    "        raise Exception(\"Must supply an article title to make a pageinfo request.\")\n",
    "\n",
    "    # make the request\n",
    "    try:\n",
    "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
    "        # occurs during the request processing - throttling is always a good practice with a free\n",
    "        # data source like Wikipedia - or any other community sources\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(endpoint_url, headers=headers, params=request_template)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b905157e",
   "metadata": {},
   "source": [
    "Define constants and a function that gets makes an ORES request using the page title and current revision id. I am defining a constant for my access token because I only intend to distribute this notebook with myself and the instructional staff. Otherwise, I'd store the access token in a local hidden file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8a63687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    CONSTANTS\n",
    "#\n",
    "\n",
    "#    The current LiftWing ORES API endpoint and prediction model\n",
    "#\n",
    "API_ORES_LIFTWING_ENDPOINT = \"https://api.wikimedia.org/service/lw/inference/v1/models/{model_name}:predict\"\n",
    "API_ORES_EN_QUALITY_MODEL = \"enwiki-articlequality\"\n",
    "\n",
    "#\n",
    "#    The throttling rate is a function of the Access token that you are granted when you request the token. The constants\n",
    "#    come from dissecting the token and getting the rate limits from the granted token. An example of that is below.\n",
    "#\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = (60.0/5000.0)-API_LATENCY_ASSUMED\n",
    "\n",
    "#    When making automated requests we should include something that is unique to the person making the request\n",
    "#    This should include an email - your UW email would be good to put in there\n",
    "#    \n",
    "#    Because all LiftWing API requests require some form of authentication, you need to provide your access token\n",
    "#    as part of the header too\n",
    "#\n",
    "REQUEST_HEADER_TEMPLATE = {\n",
    "    'User-Agent': \"jjoko@uw.edu, University of Washington, MSDS DATA 512 - AUTUMN 2023\",\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': \"Bearer {access_token}\"\n",
    "}\n",
    "#\n",
    "#    This is a template for the parameters that we need to supply in the headers of an API request\n",
    "#\n",
    "REQUEST_HEADER_PARAMS_TEMPLATE = {\n",
    "    'email_address' : \"jjoko@uw.edu\",         # your email address should go here\n",
    "    'access_token'  : \"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJhdWQiOiI5M2QwMmZhY2RiNDIyNDI5N2M0YzU1ZmNlMTg5MGU3MyIsImp0aSI6ImIwMmU1MjU2MmI1ZjQxNjJlODdjMGI5MjdiNTY1MTczMjg1OWI3NTcxNjc2MDk0YjQwZGIyZDExZjJkYTQ2ZjVmMWEwYzM1ZDllZDc1MGIxIiwiaWF0IjoxNjk3MjMzNDM2LjM0NDEwNiwibmJmIjoxNjk3MjMzNDM2LjM0NDEwOSwiZXhwIjozMzI1NDE0MjIzNi4zNDI3NzMsInN1YiI6IjczOTk4ODk4IiwiaXNzIjoiaHR0cHM6Ly9tZXRhLndpa2ltZWRpYS5vcmciLCJyYXRlbGltaXQiOnsicmVxdWVzdHNfcGVyX3VuaXQiOjUwMDAsInVuaXQiOiJIT1VSIn0sInNjb3BlcyI6WyJiYXNpYyJdfQ.XnUGpEA01TR6aOd2XOfYxE72cscL9tK8cJ6PKcO5v1-ufSiGu-CeKAned8zNVG8HyqyaapPUfhr8wybl0FuY6ouEVxy0oxiVlxoobYPx5uzGIpE-ubNzyZdd5sRVmiQAKWIC322bY4C3nvL7qxC_rX9MN2mXXgJ010imENg6O5mmiDd9_YMaOoWMMtKq53rZE-Eltdeyb_Lza7ryQkz51A5_YuduGHfFMfEj6PpssWscdH4m4CzqrZbTWVtjhab3jkYdEqWmzXtvgR3fZz7TzMTuZFlBNk4tIPv6aaLn-sqm1NOe0wWizMkGcdxHRl7pdnhOLhlYr8hgdfZ1Og0JBkLF44i-ztyJj6YGVFN4nC03xWRWAxGQV9DHGqMSHdWkUAXZCaI2YQ7UyNah48SLhdukUpAq1mq7KZSh5dHppM5vmPreUB4TGtaVpVPmxcObmeLrVTGdUJ5Rbs0Lr_RbcMCwa4ce0CFWeUOYjuh4-BhY15M1-98wVKBjSq_04WECrdaITwUaluRuZYqkVaI5mzwyvnVAbv3Jy98UYJXd9e2nB7fU1Bvaw4XsOrhLejmWpDrL1VfTQlv203MojrOS_DH57wdmksGOgvo-N7xSAFn8C0SwTZXJUmDbjqGqHMtHixBe9UKOSvzINrSIqOG5F12lPVcGZLyUBucoZlfdfE8\"          # the access token you create will need to go here\n",
    "}\n",
    "\n",
    "#\n",
    "#    A dictionary of English Wikipedia article titles (keys) and sample revision IDs that can be used for this ORES scoring example\n",
    "#\n",
    "ARTICLE_REVISIONS = { 'Bison':1085687913 , 'Northern flicker':1086582504 , 'Red squirrel':1083787665 , 'Chinook salmon':1085406228 , 'Horseshoe bat':1060601936 }\n",
    "\n",
    "#\n",
    "#    This is a template of the data required as a payload when making a scoring request of the ORES model\n",
    "#\n",
    "ORES_REQUEST_DATA_TEMPLATE = {\n",
    "    \"lang\":        \"en\",     # required that its english - we're scoring English Wikipedia revisions\n",
    "    \"rev_id\":      \"\",       # this request requires a revision id\n",
    "    \"features\":    True\n",
    "}\n",
    "\n",
    "#\n",
    "#    These are used later - defined here so they, at least, have empty values\n",
    "#\n",
    "USERNAME = \"Jamesjoko\"\n",
    "ACCESS_TOKEN = \"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJhdWQiOiI5M2QwMmZhY2RiNDIyNDI5N2M0YzU1ZmNlMTg5MGU3MyIsImp0aSI6ImIwMmU1MjU2MmI1ZjQxNjJlODdjMGI5MjdiNTY1MTczMjg1OWI3NTcxNjc2MDk0YjQwZGIyZDExZjJkYTQ2ZjVmMWEwYzM1ZDllZDc1MGIxIiwiaWF0IjoxNjk3MjMzNDM2LjM0NDEwNiwibmJmIjoxNjk3MjMzNDM2LjM0NDEwOSwiZXhwIjozMzI1NDE0MjIzNi4zNDI3NzMsInN1YiI6IjczOTk4ODk4IiwiaXNzIjoiaHR0cHM6Ly9tZXRhLndpa2ltZWRpYS5vcmciLCJyYXRlbGltaXQiOnsicmVxdWVzdHNfcGVyX3VuaXQiOjUwMDAsInVuaXQiOiJIT1VSIn0sInNjb3BlcyI6WyJiYXNpYyJdfQ.XnUGpEA01TR6aOd2XOfYxE72cscL9tK8cJ6PKcO5v1-ufSiGu-CeKAned8zNVG8HyqyaapPUfhr8wybl0FuY6ouEVxy0oxiVlxoobYPx5uzGIpE-ubNzyZdd5sRVmiQAKWIC322bY4C3nvL7qxC_rX9MN2mXXgJ010imENg6O5mmiDd9_YMaOoWMMtKq53rZE-Eltdeyb_Lza7ryQkz51A5_YuduGHfFMfEj6PpssWscdH4m4CzqrZbTWVtjhab3jkYdEqWmzXtvgR3fZz7TzMTuZFlBNk4tIPv6aaLn-sqm1NOe0wWizMkGcdxHRl7pdnhOLhlYr8hgdfZ1Og0JBkLF44i-ztyJj6YGVFN4nC03xWRWAxGQV9DHGqMSHdWkUAXZCaI2YQ7UyNah48SLhdukUpAq1mq7KZSh5dHppM5vmPreUB4TGtaVpVPmxcObmeLrVTGdUJ5Rbs0Lr_RbcMCwa4ce0CFWeUOYjuh4-BhY15M1-98wVKBjSq_04WECrdaITwUaluRuZYqkVaI5mzwyvnVAbv3Jy98UYJXd9e2nB7fU1Bvaw4XsOrhLejmWpDrL1VfTQlv203MojrOS_DH57wdmksGOgvo-N7xSAFn8C0SwTZXJUmDbjqGqHMtHixBe9UKOSvzINrSIqOG5F12lPVcGZLyUBucoZlfdfE8\"\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9c28442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    PROCEDURES/FUNCTIONS\n",
    "#\n",
    "\n",
    "def request_ores_score_per_article(article_revid = None, email_address=None, access_token=None,\n",
    "                                   endpoint_url = API_ORES_LIFTWING_ENDPOINT, \n",
    "                                   model_name = API_ORES_EN_QUALITY_MODEL, \n",
    "                                   request_data = ORES_REQUEST_DATA_TEMPLATE, \n",
    "                                   header_format = REQUEST_HEADER_TEMPLATE, \n",
    "                                   header_params = REQUEST_HEADER_PARAMS_TEMPLATE):\n",
    "    \n",
    "    #    Make sure we have an article revision id, email and token\n",
    "    #    This approach prioritizes the parameters passed in when making the call\n",
    "    if article_revid:\n",
    "        request_data['rev_id'] = article_revid\n",
    "    if email_address:\n",
    "        header_params['email_address'] = email_address\n",
    "    if access_token:\n",
    "        header_params['access_token'] = access_token\n",
    "    \n",
    "    #   Making a request requires a revision id - an email address - and the access token\n",
    "    if not request_data['rev_id']:\n",
    "        raise Exception(\"Must provide an article revision id (rev_id) to score articles\")\n",
    "    if not header_params['email_address']:\n",
    "        raise Exception(\"Must provide an 'email_address' value\")\n",
    "    if not header_params['access_token']:\n",
    "        raise Exception(\"Must provide an 'access_token' value\")\n",
    "    \n",
    "    # Create the request URL with the specified model parameter - default is a article quality score request\n",
    "    request_url = endpoint_url.format(model_name=model_name)\n",
    "    \n",
    "    # Create a compliant request header from the template and the supplied parameters\n",
    "    headers = dict()\n",
    "    for key in header_format.keys():\n",
    "        headers[str(key)] = header_format[key].format(**header_params)\n",
    "    \n",
    "    # make the request\n",
    "    try:\n",
    "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
    "        # occurs during the request processing - throttling is always a good practice with a free data\n",
    "        # source like ORES - or other community sources\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        #response = requests.get(request_url, headers=headers)\n",
    "        response = requests.post(request_url, headers=headers, data=json.dumps(request_data))\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954a3572",
   "metadata": {},
   "source": [
    "a) read each line of us_cities_by_state_SEPT.2023.csv, b) make a page info request to get the current article page revision, and c) then make an ORES request using the page title and current revision id.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "bd0a829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "revision_ids = []\n",
    "for idx in range(0, len(cities)):\n",
    "    try:\n",
    "        row = cities.iloc[idx]\n",
    "        revision_id = list(request_pageinfo_per_article(row[\"page_title\"])[\"query\"][\"pages\"].values())[0][\"lastrevid\"]\n",
    "        row[\"revision_id\"] = revision_id\n",
    "        score = request_ores_score_per_article(article_revid=revision_id,\n",
    "                                           email_address=\"jjoko@uw.edu\",\n",
    "                                           access_token=ACCESS_TOKEN)[\"enwiki\"][\"scores\"][str(revision_id)][\"articlequality\"][\"score\"][\"prediction\"]\n",
    "        row[\"article_quality\"] = score\n",
    "    except TypeError:\n",
    "        print(f\"Error on row index:{idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "0f8c6c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>page_title</th>\n",
       "      <th>url</th>\n",
       "      <th>revision_id</th>\n",
       "      <th>article_quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Abbeville, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abbeville,_Alabama</td>\n",
       "      <td>1171163550</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Adamsville, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Adamsville,_Alabama</td>\n",
       "      <td>1177621427</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Addison, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Addison,_Alabama</td>\n",
       "      <td>1168359898</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Akron, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Akron,_Alabama</td>\n",
       "      <td>1165909508</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabaster, Alabama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Alabaster,_Alabama</td>\n",
       "      <td>1179139816</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     state           page_title  \\\n",
       "0  Alabama   Abbeville, Alabama   \n",
       "1  Alabama  Adamsville, Alabama   \n",
       "2  Alabama     Addison, Alabama   \n",
       "3  Alabama       Akron, Alabama   \n",
       "4  Alabama   Alabaster, Alabama   \n",
       "\n",
       "                                                 url  revision_id  \\\n",
       "0   https://en.wikipedia.org/wiki/Abbeville,_Alabama   1171163550   \n",
       "1  https://en.wikipedia.org/wiki/Adamsville,_Alabama   1177621427   \n",
       "2     https://en.wikipedia.org/wiki/Addison,_Alabama   1168359898   \n",
       "3       https://en.wikipedia.org/wiki/Akron,_Alabama   1165909508   \n",
       "4   https://en.wikipedia.org/wiki/Alabaster,_Alabama   1179139816   \n",
       "\n",
       "  article_quality  \n",
       "0               C  \n",
       "1               C  \n",
       "2               C  \n",
       "3              GA  \n",
       "4               C  "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities.to_csv(\"intermediate_data/us_cities_article_quality.csv\", index = False)\n",
    "pd.read_csv(\"intermediate_data/us_cities_article_quality.csv\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "d25b732f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C        12926\n",
       "GA        4727\n",
       "Start     2102\n",
       "B          883\n",
       "Stub       677\n",
       "FA         210\n",
       "Name: article_quality, dtype: int64"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities[\"article_quality\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da539b37",
   "metadata": {},
   "source": [
    "I was able to get ORES scores for every article.\n",
    "# Step 3: Combining the Datasets\n",
    "Merge the us cities article dataset, population dataset, and regional division dataset together. The populaiton dataset contains some non-states and extra information. The result should contain the following columns: state, regional_division, population, article_title, revision_id, article_quality.\n",
    "\n",
    "First, load the population dataset into memory and pre-process it by removing non-states and extra information and fixing the state column, then inner joining on state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "29287930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>5049846.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>734182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>7264877.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>3028122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>39142991.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        state  population\n",
       "0     Alabama   5049846.0\n",
       "1      Alaska    734182.0\n",
       "2     Arizona   7264877.0\n",
       "3    Arkansas   3028122.0\n",
       "4  California  39142991.0"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population = pd.read_excel(\"starting_data/NST-EST2022-POP.xlsx\").iloc[8:-6,[0, 3]].reset_index(drop = True).dropna()\n",
    "population.columns = [\"state\", \"population\"]\n",
    "population[\"state\"] = [a[1:].replace(\" \", \"_\") for a in population[\"state\"]]\n",
    "population.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "0c87fbd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>3623355.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>District_of_Columbia</td>\n",
       "      <td>668791.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>10788029.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Nebraska</td>\n",
       "      <td>1963554.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   state  population\n",
       "6            Connecticut   3623355.0\n",
       "8   District_of_Columbia    668791.0\n",
       "10               Georgia  10788029.0\n",
       "27              Nebraska   1963554.0"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population[~population['state'].isin(cities['state'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "7ed927e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Georgia_(U.S._state)'], dtype=object)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities[~cities['state'].isin(population['state'])][\"state\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d42804d",
   "metadata": {},
   "source": [
    "The us_cities dataset is missing Connecticut, Nebraska, and District of Columbia. Georgia also needs to be reformatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "dbd8d745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>page_title</th>\n",
       "      <th>url</th>\n",
       "      <th>revision_id</th>\n",
       "      <th>article_quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>Abbeville, Georgia</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Abbeville,_Georgia</td>\n",
       "      <td>1171167087</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2443</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>Acworth, Georgia</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Acworth,_Georgia</td>\n",
       "      <td>1166760529</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2444</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>Adairsville, Georgia</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Adairsville,_Geo...</td>\n",
       "      <td>1165502646</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>Adel, Georgia</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Adel,_Georgia</td>\n",
       "      <td>1168374078</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2446</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>Adrian, Georgia</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Adrian,_Georgia</td>\n",
       "      <td>1176950695</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        state            page_title  \\\n",
       "2442  Georgia    Abbeville, Georgia   \n",
       "2443  Georgia      Acworth, Georgia   \n",
       "2444  Georgia  Adairsville, Georgia   \n",
       "2445  Georgia         Adel, Georgia   \n",
       "2446  Georgia       Adrian, Georgia   \n",
       "\n",
       "                                                    url revision_id  \\\n",
       "2442   https://en.wikipedia.org/wiki/Abbeville,_Georgia  1171167087   \n",
       "2443     https://en.wikipedia.org/wiki/Acworth,_Georgia  1166760529   \n",
       "2444  https://en.wikipedia.org/wiki/Adairsville,_Geo...  1165502646   \n",
       "2445        https://en.wikipedia.org/wiki/Adel,_Georgia  1168374078   \n",
       "2446      https://en.wikipedia.org/wiki/Adrian,_Georgia  1176950695   \n",
       "\n",
       "     article_quality  \n",
       "2442               C  \n",
       "2443               C  \n",
       "2444               C  \n",
       "2445               C  \n",
       "2446               C  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities.loc[cities[\"state\"].str.contains(\"Georgia\"), \"state\"] = \"Georgia\"\n",
    "cities.loc[cities[\"state\"] == \"Georgia\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "77278e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.read_excel(\"starting_data/US States by Region - US Census Bureau.xlsx\")[\"STATE\"].dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ef6ef7",
   "metadata": {},
   "source": [
    "Next, load the regional division dataset into memory and preprocess it by repairing the schema to regional division and state and then inner joining on state. Lastly, fix the structure of the merged dataset to match the homework handout and write to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "31700e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regional_division = pd.read_excel(\"starting_data/US States by Region - US Census Bureau.xlsx\").iloc[:, 1:].dropna(how='all').reset_index(drop = True)\n",
    "for idx, row in regional_division.iterrows():\n",
    "    if pd.isna(row[\"DIVISION\"]):\n",
    "        row[\"DIVISION\"] = regional_division.iloc[idx-1, 0]\n",
    "regional_division = regional_division.dropna()\n",
    "regional_division.columns = [\"regional_division\", \"state\"]\n",
    "regional_division[\"state\"] = regional_division[\"state\"].str.replace(\" \", \"_\")\n",
    "len(regional_division[\"state\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "58704200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>regional_division</th>\n",
       "      <th>population</th>\n",
       "      <th>article_title</th>\n",
       "      <th>revision_id</th>\n",
       "      <th>article_quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>East South Central</td>\n",
       "      <td>5049846.0</td>\n",
       "      <td>Abbeville, Alabama</td>\n",
       "      <td>1171163550</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>East South Central</td>\n",
       "      <td>5049846.0</td>\n",
       "      <td>Adamsville, Alabama</td>\n",
       "      <td>1177621427</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>East South Central</td>\n",
       "      <td>5049846.0</td>\n",
       "      <td>Addison, Alabama</td>\n",
       "      <td>1168359898</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>East South Central</td>\n",
       "      <td>5049846.0</td>\n",
       "      <td>Akron, Alabama</td>\n",
       "      <td>1165909508</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>East South Central</td>\n",
       "      <td>5049846.0</td>\n",
       "      <td>Alabaster, Alabama</td>\n",
       "      <td>1179139816</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     state   regional_division  population        article_title revision_id  \\\n",
       "0  Alabama  East South Central   5049846.0   Abbeville, Alabama  1171163550   \n",
       "1  Alabama  East South Central   5049846.0  Adamsville, Alabama  1177621427   \n",
       "2  Alabama  East South Central   5049846.0     Addison, Alabama  1168359898   \n",
       "3  Alabama  East South Central   5049846.0       Akron, Alabama  1165909508   \n",
       "4  Alabama  East South Central   5049846.0   Alabaster, Alabama  1179139816   \n",
       "\n",
       "  article_quality  \n",
       "0               C  \n",
       "1               C  \n",
       "2               C  \n",
       "3              GA  \n",
       "4               C  "
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.merge(cities, population, on='state', how='left')\n",
    "merged = pd.merge(merged, regional_division, on='state', how='left')\n",
    "merged = merged[[\"state\", \"regional_division\", \"population\", \"page_title\", \"revision_id\", \"article_quality\"]]\n",
    "merged.columns = [\"state\", \"regional_division\", \"population\", \"article_title\", \"revision_id\", \"article_quality\"]\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "5f0a64a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>regional_division</th>\n",
       "      <th>population</th>\n",
       "      <th>article_title</th>\n",
       "      <th>revision_id</th>\n",
       "      <th>article_quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>East South Central</td>\n",
       "      <td>5049846.0</td>\n",
       "      <td>Abbeville, Alabama</td>\n",
       "      <td>1171163550</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>East South Central</td>\n",
       "      <td>5049846.0</td>\n",
       "      <td>Adamsville, Alabama</td>\n",
       "      <td>1177621427</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>East South Central</td>\n",
       "      <td>5049846.0</td>\n",
       "      <td>Addison, Alabama</td>\n",
       "      <td>1168359898</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>East South Central</td>\n",
       "      <td>5049846.0</td>\n",
       "      <td>Akron, Alabama</td>\n",
       "      <td>1165909508</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>East South Central</td>\n",
       "      <td>5049846.0</td>\n",
       "      <td>Alabaster, Alabama</td>\n",
       "      <td>1179139816</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     state   regional_division  population        article_title  revision_id  \\\n",
       "0  Alabama  East South Central   5049846.0   Abbeville, Alabama   1171163550   \n",
       "1  Alabama  East South Central   5049846.0  Adamsville, Alabama   1177621427   \n",
       "2  Alabama  East South Central   5049846.0     Addison, Alabama   1168359898   \n",
       "3  Alabama  East South Central   5049846.0       Akron, Alabama   1165909508   \n",
       "4  Alabama  East South Central   5049846.0   Alabaster, Alabama   1179139816   \n",
       "\n",
       "  article_quality  \n",
       "0               C  \n",
       "1               C  \n",
       "2               C  \n",
       "3              GA  \n",
       "4               C  "
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.to_csv(\"wp_scored_city_articles_by_state.csv\", index = False)\n",
    "pd.read_csv(\"wp_scored_city_articles_by_state.csv\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d15d51",
   "metadata": {},
   "source": [
    "# Step 4: Analysis and Step 5: Results\n",
    "First, to caluclate total articles per population, I get the number of rows per state (# articles) and divide it by the population of the state. Below is the Top 10 US states by coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "0efc6152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>total_articles_by_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>0.000509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>North_Dakota</td>\n",
       "      <td>0.000458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Maine</td>\n",
       "      <td>0.000351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South_Dakota</td>\n",
       "      <td>0.000347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>0.000326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>0.000203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>0.000196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>0.000177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>0.000171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>New_Hampshire</td>\n",
       "      <td>0.000169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           state  total_articles_by_capita\n",
       "0        Vermont                  0.000509\n",
       "1   North_Dakota                  0.000458\n",
       "2          Maine                  0.000351\n",
       "3   South_Dakota                  0.000347\n",
       "4           Iowa                  0.000326\n",
       "5         Alaska                  0.000203\n",
       "6   Pennsylvania                  0.000196\n",
       "7       Michigan                  0.000177\n",
       "8        Wyoming                  0.000171\n",
       "9  New_Hampshire                  0.000169"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_by_coverage = pd.DataFrame(merged[\"state\"].value_counts() / merged[\"state\"].value_counts().index.map(dict(zip(population.state, population.population)))).reset_index()\n",
    "states_by_coverage.columns = [\"state\", \"total_articles_by_capita\"]\n",
    "states_by_coverage = states_by_coverage.sort_values(by=\"total_articles_by_capita\", ascending=False).reset_index(drop = True)\n",
    "states_by_coverage.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b91b658",
   "metadata": {},
   "source": [
    "Below is the Bottom 10 US states by coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "afde856d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>total_articles_by_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>North_Carolina</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>California</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Florida</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             state  total_articles_by_capita\n",
       "47  North_Carolina                  0.000005\n",
       "46          Nevada                  0.000006\n",
       "45      California                  0.000012\n",
       "44         Arizona                  0.000013\n",
       "43        Virginia                  0.000015\n",
       "42        Oklahoma                  0.000019\n",
       "41         Florida                  0.000019\n",
       "40          Kansas                  0.000021\n",
       "39        Maryland                  0.000025\n",
       "38       Wisconsin                  0.000033"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_by_coverage.tail(10).sort_values(by=\"total_articles_by_capita\", ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79875f80",
   "metadata": {},
   "source": [
    "Second, to caluclate total high quality articles per population, I make a dataframe of only high quality articles, get the number of rows per state (# articles), and divide it by the population of the state. Below is the Top 10 US states by by high quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "177b40c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_quality = merged[(merged[\"article_quality\"] == \"FA\") | (merged[\"article_quality\"] == \"GA\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "bc157517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>total_high_quality_articles_by_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South_Dakota</td>\n",
       "      <td>0.000062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>West_Virginia</td>\n",
       "      <td>0.000059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Montana</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>New_Hampshire</td>\n",
       "      <td>0.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Missouri</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>New_Jersey</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           state  total_high_quality_articles_by_capita\n",
       "0        Vermont                               0.000070\n",
       "1        Wyoming                               0.000067\n",
       "2   South_Dakota                               0.000062\n",
       "3  West_Virginia                               0.000059\n",
       "4        Montana                               0.000050\n",
       "5  New_Hampshire                               0.000045\n",
       "6   Pennsylvania                               0.000043\n",
       "7       Missouri                               0.000043\n",
       "8         Alaska                               0.000042\n",
       "9     New_Jersey                               0.000041"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_by_high_qual = pd.DataFrame(high_quality[\"state\"].value_counts() / high_quality[\"state\"].value_counts().index.map(dict(zip(population.state, population.population)))).reset_index()\n",
    "states_by_high_qual.columns = [\"state\", \"total_high_quality_articles_by_capita\"]\n",
    "states_by_high_qual = states_by_high_qual.sort_values(by=\"total_high_quality_articles_by_capita\", ascending=False).reset_index(drop = True)\n",
    "states_by_high_qual.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0138667d",
   "metadata": {},
   "source": [
    "Below is the Bottom 10 US states by by high quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "5bf5fcb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>total_high_quality_articles_by_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>North_Carolina</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>California</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Florida</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>New_York</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             state  total_high_quality_articles_by_capita\n",
       "47  North_Carolina                               0.000002\n",
       "46        Virginia                               0.000002\n",
       "45          Nevada                               0.000003\n",
       "44         Arizona                               0.000003\n",
       "43      California                               0.000004\n",
       "42         Florida                               0.000005\n",
       "41        New_York                               0.000006\n",
       "40        Maryland                               0.000007\n",
       "39          Kansas                               0.000007\n",
       "38        Oklahoma                               0.000008"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_by_high_qual.tail(10).sort_values(by=\"total_high_quality_articles_by_capita\", ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39573db7",
   "metadata": {},
   "source": [
    "Lastly, to caluclate total and high quality articles per population by division, I make a dataframe of population per division to aid the calculations. To calculate the total coverage, I get the number of rows per division (# articles), and divide it by the population of the division. To calculate the high quality coverage, I make a dataframe of only high quality articles, get the number of rows per division (# articles), and divide it by the population of the division."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "90d4d926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "regional_division\n",
       "South Atlantic        65997557.0\n",
       "Pacific               53321373.0\n",
       "East North Central    47181948.0\n",
       "Middle Atlantic       42137512.0\n",
       "West South Central    41205309.0\n",
       "Mountain              25268390.0\n",
       "West North Central    21654557.0\n",
       "East South Central    19474372.0\n",
       "New England           15121745.0\n",
       "Name: population, dtype: float64"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regional_division_population = pd.merge(regional_division, population, on=\"state\", how=\"left\").groupby(\"regional_division\")[\"population\"].sum()\n",
    "regional_division_population.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aba3311",
   "metadata": {},
   "source": [
    "Below is the rank ordered list of US census divisions (in descending order) by total articles per capita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "7d4fc698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regional_division</th>\n",
       "      <th>total_articles_by_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>West North Central</td>\n",
       "      <td>0.000165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>East North Central</td>\n",
       "      <td>0.000101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New England</td>\n",
       "      <td>0.000095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Middle Atlantic</td>\n",
       "      <td>0.000090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>East South Central</td>\n",
       "      <td>0.000079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West South Central</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    regional_division  total_articles_by_capita\n",
       "0  West North Central                  0.000165\n",
       "1  East North Central                  0.000101\n",
       "2         New England                  0.000095\n",
       "3     Middle Atlantic                  0.000090\n",
       "4  East South Central                  0.000079\n",
       "5  West South Central                  0.000051\n",
       "6            Mountain                  0.000047\n",
       "7      South Atlantic                  0.000028\n",
       "8             Pacific                  0.000024"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regional_division_by_coverage = pd.DataFrame(merged[\"regional_division\"].value_counts() / merged[\"regional_division\"].value_counts().index.map(regional_division_population)).reset_index()\n",
    "regional_division_by_coverage.columns = [\"regional_division\", \"total_articles_by_capita\"]\n",
    "regional_division_by_coverage = regional_division_by_coverage.sort_values(by=\"total_articles_by_capita\", ascending=False).reset_index(drop = True)\n",
    "regional_division_by_coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf66e19",
   "metadata": {},
   "source": [
    "Below is the rank ordered list of US census divisions (in descending order) by high quality articles per capita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "b41b58a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regional_division</th>\n",
       "      <th>total_high_quality_articles_by_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>West North Central</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Middle Atlantic</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>East South Central</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>West South Central</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>East North Central</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>New England</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    regional_division  total_high_quality_articles_by_capita\n",
       "0  West North Central                               0.000030\n",
       "1     Middle Atlantic                               0.000025\n",
       "2  East South Central                               0.000016\n",
       "3  West South Central                               0.000015\n",
       "4  East North Central                               0.000015\n",
       "5         New England                               0.000015\n",
       "6            Mountain                               0.000013\n",
       "7             Pacific                               0.000009\n",
       "8      South Atlantic                               0.000008"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regional_division_by_high_qual = pd.DataFrame(high_quality[\"regional_division\"].value_counts() / high_quality[\"regional_division\"].value_counts().index.map(regional_division_population)).reset_index()\n",
    "regional_division_by_high_qual.columns = [\"regional_division\", \"total_high_quality_articles_by_capita\"]\n",
    "regional_division_by_high_qual = regional_division_by_high_qual.sort_values(by=\"total_high_quality_articles_by_capita\", ascending=False).reset_index(drop = True)\n",
    "regional_division_by_high_qual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "0bf463c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pennsylvania      566\n",
       "Texas             487\n",
       "New_Jersey        379\n",
       "Missouri          263\n",
       "Ohio              202\n",
       "Illinois          196\n",
       "California        172\n",
       "Minnesota         169\n",
       "Tennessee         146\n",
       "Oregon            141\n",
       "Michigan          133\n",
       "Indiana           124\n",
       "Florida           119\n",
       "Washington        115\n",
       "New_York          111\n",
       "West_Virginia     105\n",
       "Iowa              104\n",
       "South_Carolina    103\n",
       "Georgia            93\n",
       "Kentucky           79\n",
       "Colorado           77\n",
       "Arkansas           72\n",
       "New_Hampshire      63\n",
       "Massachusetts      62\n",
       "Utah               61\n",
       "Wisconsin          60\n",
       "South_Dakota       56\n",
       "Montana            55\n",
       "Alabama            53\n",
       "Vermont            45\n",
       "Louisiana          44\n",
       "Maine              43\n",
       "Maryland           42\n",
       "Idaho              41\n",
       "Mississippi        39\n",
       "Wyoming            39\n",
       "Alaska             31\n",
       "Oklahoma           31\n",
       "New_Mexico         31\n",
       "Hawaii             30\n",
       "North_Dakota       26\n",
       "Delaware           25\n",
       "Arizona            24\n",
       "Kansas             22\n",
       "North_Carolina     20\n",
       "Virginia           18\n",
       "Rhode_Island       12\n",
       "Nevada              8\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_quality[\"state\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "f075b9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pennsylvania      2556\n",
       "Michigan          1773\n",
       "Illinois          1298\n",
       "Texas             1224\n",
       "Iowa              1043\n",
       "Missouri           951\n",
       "Ohio               926\n",
       "Minnesota          854\n",
       "New_York           661\n",
       "Indiana            565\n",
       "New_Jersey         564\n",
       "Georgia            538\n",
       "Arkansas           500\n",
       "Maine              483\n",
       "California         482\n",
       "Alabama            461\n",
       "Kentucky           421\n",
       "Florida            412\n",
       "North_Dakota       356\n",
       "Massachusetts      352\n",
       "Tennessee          347\n",
       "Vermont            329\n",
       "South_Dakota       311\n",
       "Louisiana          304\n",
       "Mississippi        300\n",
       "Colorado           290\n",
       "Washington         281\n",
       "South_Carolina     271\n",
       "Utah               255\n",
       "Oregon             241\n",
       "New_Hampshire      234\n",
       "West_Virginia      232\n",
       "Idaho              201\n",
       "Wisconsin          192\n",
       "Maryland           157\n",
       "Hawaii             151\n",
       "Alaska             149\n",
       "Virginia           133\n",
       "Montana            128\n",
       "New_Mexico         106\n",
       "Wyoming             99\n",
       "Arizona             91\n",
       "Oklahoma            75\n",
       "Kansas              63\n",
       "Delaware            57\n",
       "North_Carolina      50\n",
       "Rhode_Island        39\n",
       "Nevada              19\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities[\"state\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "e13c01ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>California</td>\n",
       "      <td>39142991.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Texas</td>\n",
       "      <td>29558864.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Florida</td>\n",
       "      <td>21828069.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New_York</td>\n",
       "      <td>19857492.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>13012059.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>12686469.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>11764342.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>10788029.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>North_Carolina</td>\n",
       "      <td>10565885.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>10037504.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>New_Jersey</td>\n",
       "      <td>9267961.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>8657365.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Washington</td>\n",
       "      <td>7740745.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>7264877.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>6989690.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>6968351.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>6813532.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>6174610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Missouri</td>\n",
       "      <td>6169823.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>5880101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>5811297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>5711471.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>South_Carolina</td>\n",
       "      <td>5193266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>5049846.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>4627098.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>4506589.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Oregon</td>\n",
       "      <td>4256301.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>3991225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>3623355.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Utah</td>\n",
       "      <td>3339113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>3197689.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>3146402.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>3028122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>2949586.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>2937922.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>New_Mexico</td>\n",
       "      <td>2116677.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Nebraska</td>\n",
       "      <td>1963554.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>1904314.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>West_Virginia</td>\n",
       "      <td>1785526.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Hawaii</td>\n",
       "      <td>1447154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>New_Hampshire</td>\n",
       "      <td>1387505.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Maine</td>\n",
       "      <td>1377238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Montana</td>\n",
       "      <td>1106227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Rhode_Island</td>\n",
       "      <td>1096985.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>1004807.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>South_Dakota</td>\n",
       "      <td>896164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>North_Dakota</td>\n",
       "      <td>777934.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>734182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>District_of_Columbia</td>\n",
       "      <td>668791.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>646972.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>579483.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   state  population\n",
       "0             California  39142991.0\n",
       "1                  Texas  29558864.0\n",
       "2                Florida  21828069.0\n",
       "3               New_York  19857492.0\n",
       "4           Pennsylvania  13012059.0\n",
       "5               Illinois  12686469.0\n",
       "6                   Ohio  11764342.0\n",
       "7                Georgia  10788029.0\n",
       "8         North_Carolina  10565885.0\n",
       "9               Michigan  10037504.0\n",
       "10            New_Jersey   9267961.0\n",
       "11              Virginia   8657365.0\n",
       "12            Washington   7740745.0\n",
       "13               Arizona   7264877.0\n",
       "14         Massachusetts   6989690.0\n",
       "15             Tennessee   6968351.0\n",
       "16               Indiana   6813532.0\n",
       "17              Maryland   6174610.0\n",
       "18              Missouri   6169823.0\n",
       "19             Wisconsin   5880101.0\n",
       "20              Colorado   5811297.0\n",
       "21             Minnesota   5711471.0\n",
       "22        South_Carolina   5193266.0\n",
       "23               Alabama   5049846.0\n",
       "24             Louisiana   4627098.0\n",
       "25              Kentucky   4506589.0\n",
       "26                Oregon   4256301.0\n",
       "27              Oklahoma   3991225.0\n",
       "28           Connecticut   3623355.0\n",
       "29                  Utah   3339113.0\n",
       "30                  Iowa   3197689.0\n",
       "31                Nevada   3146402.0\n",
       "32              Arkansas   3028122.0\n",
       "33           Mississippi   2949586.0\n",
       "34                Kansas   2937922.0\n",
       "35            New_Mexico   2116677.0\n",
       "36              Nebraska   1963554.0\n",
       "37                 Idaho   1904314.0\n",
       "38         West_Virginia   1785526.0\n",
       "39                Hawaii   1447154.0\n",
       "40         New_Hampshire   1387505.0\n",
       "41                 Maine   1377238.0\n",
       "42               Montana   1106227.0\n",
       "43          Rhode_Island   1096985.0\n",
       "44              Delaware   1004807.0\n",
       "45          South_Dakota    896164.0\n",
       "46          North_Dakota    777934.0\n",
       "47                Alaska    734182.0\n",
       "48  District_of_Columbia    668791.0\n",
       "49               Vermont    646972.0\n",
       "50               Wyoming    579483.0"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population.sort_values(\"population\", ascending=False).reset_index(drop = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
